{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy is an open-source software library for advanced natural language processing, written in Cython.\n",
    "<br>\n",
    "It's focus is on providing software for production usage and excels at large-scale information extraction tasks.\n",
    "<br>\n",
    "\n",
    "spaCy provides the following key features:\n",
    "<ol>\n",
    "    <li>Non-destructive tokenization</li>\n",
    "    <li>Named entity recognition</li>\n",
    "    <li>\"Alpha tokenization\" support for over 25 languages</li>\n",
    "    <li>Statistical models models for 8 languages</li>\n",
    "    <li>Pre-trained word vectors</li>\n",
    "    <li>Part-of-speech tagging</li>\n",
    "    <li>Labelled dependency parsing</li>\n",
    "    <li>Syntax-driven sentence segmentation</li>\n",
    "    <li>Text classification</li>\n",
    "    <li>Built-in visualizers for syntax and named entities</li>\n",
    "    <li>Deep learning integration</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "train_data = pd.read_csv('../data/train.csv')\n",
    "test_data = pd.read_csv('../data/test.csv')\n",
    "\n",
    "train_data = train_data[:400000]\n",
    "\n",
    "train_text = train_data['question_text'].values\n",
    "train_labels = train_data['target'].values\n",
    "\n",
    "test_text = test_data['question_text'].values\n",
    "test_qid = test_data['qid'].values\n",
    "\n",
    "# load the Spacy model\n",
    "spacy_model = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that we can do with the data is to convert all the letters to lowecase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lowercase\n",
    "train_text = [token.lower() for token in train_text]\n",
    "test_text = [token.lower() for token in test_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call <b>spacy_model</b> on a text, spaCy first tokenizes the text to produce a Doc object. The Doc is then processed in several different steps – this is also referred to as the processing pipeline. \n",
    "\n",
    "<img src=\"processing.png\" alt=\"processing\">\n",
    "\n",
    "<br>\n",
    "where <b>tagger</b> assigns pat-of-speech tags, <b>parser</b> assigns dependency labels and <b>ner</b> detects and labels named entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is the task of splitting a text into meaningful segments, called tokens.\n",
    "<br>\n",
    "The input to the tokenizer is a unicode text, and the output is a Doc object, which is a sequence of tokens.\n",
    "\n",
    "SpaCy introduces a novel tokenization algorithm, that gives a better balance between performance, ease of definition, and ease of alignment into the original string.\n",
    "<br><br>\n",
    "The tokenization algorithm is done in the following steps:\n",
    "<ol>\n",
    "    <li>Iterate over space-separated substrings.</li>\n",
    "    <li>Check whether we have an explicitly defined rule for this substring. If we do, use it.</li>\n",
    "    <li>Otherwise, try to consume a prefix.</li>\n",
    "    <li>If we consumed a prefix, go back to the beginning of the loop, so that special-cases always get priority.</li>\n",
    "    <li>If we didn't consume a prefix, try to consume a suffix.</li>\n",
    "    <li>If we can't consume a prefix or suffix, look for \"infixes\" — stuff like hyphens etc.</li>\n",
    "    <li>Once we can't consume any more of the string, handle it as a single token.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(spacy_model.vocab)\n",
    "\n",
    "tokenized_words_train = [tokenizer(sent) for sent in train_text]\n",
    "tokenized_words_test = [tokenizer(sent) for sent in test_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('tokenized_words_spacy_train', tokenized_words_train)\n",
    "np.save('tokenized_words_spacy_test', tokenized_words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_words_train = np.load('tokenized_words_spacy_train.npy')\n",
    "tokenized_words_test = np.load('tokenized_words_spacy_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[how did quebec nationalists see their province as a nation in the 1960s?,\n",
       " do you have an adopted dog, how would you encourage people to adopt and not shop?,\n",
       " why does velocity affect time? does velocity affect space geometry?,\n",
       " how did otto von guericke used the magdeburg hemispheres?,\n",
       " can i convert montra helicon d to a mountain bike by just changing the tyres?]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_words_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation and numbers\n",
    "tokenized_words_train = [[word for word in sent if word.is_alpha] for sent in tokenized_words_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[how, did, quebec, nationalists, see, their, province, as, a, nation, in, the]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_words_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-ASCII characters\n",
    "tokenized_words_train_flat = [item for sublist in tokenized_words_train for item in sublist]\n",
    "\n",
    "cleaned_data = [re.sub(r'[^\\x00-\\x7f]', r'', word.text) for word in tokenized_words_train_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove low-frequency words\n",
    "freq_words = Counter(cleaned_data)\n",
    "\n",
    "cleaned_data = { key : value for key, value in freq_words.items() if value > 10 }\n",
    "\n",
    "filtered_data = []\n",
    "temp_array = []\n",
    "\n",
    "for sent in tokenized_words_train:\n",
    "    for word in sent:\n",
    "        if word.text in cleaned_data.keys():\n",
    "            temp_array.append(word)\n",
    "    filtered_data.append(temp_array)\n",
    "    temp_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-52c046d9462e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfreq_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "# freq_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "# filtered_data = [[word for word in sent if word.is_stop == False] for sent in tokenized_words_train]\n",
    "\n",
    "filtered_data_no_stopwords = [[word for word in sent if word.is_stop == False] for sent in filtered_data]\n",
    "\n",
    "filtered_data = filtered_data_no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[quebec, nationalists, province, nation],\n",
       " [adopted, encourage, people, adopt],\n",
       " [velocity, affect, velocity, affect, space],\n",
       " [otto, von],\n",
       " [convert, d, mountain, bike, changing]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "filtered_data_no_lemma = [[word.lemma_ for word in sent] for sent in filtered_data]\n",
    "\n",
    "filtered_data = filtered_data_no_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['quebec', 'nationalist', 'province', 'nation'],\n",
       " ['adopt', 'encourage', 'people', 'adopt'],\n",
       " ['velocity', 'affect', 'velocity', 'affect', 'space'],\n",
       " ['otto', 'von'],\n",
       " ['convert', 'have', 'mountain', 'bike', 'change']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedding is the collective name for a set of language modeling and feature learning techniques in natural language processing where words or phrases from the vocabulary are mapped to vectors of real numbers.\n",
    "<br>\n",
    "Word2Vec is one of the most popular technique to learn word embeddings using shallow neural network. It was developed by Tomas Mikolov in 2013 at Google.\n",
    "<br>\n",
    "It tries to make words with similar context occupy close spatial positions.\n",
    "<br><br>\n",
    "The Word2Vec model can be obtained using 2 techniques: \n",
    "<ol>\n",
    "    <li>Skip Gram</li>\n",
    "    <li>Common Bag Of Words (CBOW)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_wiki = KeyedVectors.load_word2vec_format('../data/wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[embed_wiki[word] for word in sent if word in embed_wiki.vocab] for sent in filtered_data] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.2429,  0.0972,  0.09  ,  0.2347, -0.0141,  0.1991,  0.3137,\n",
       "        -0.054 , -0.0527, -0.1223,  0.0317,  0.0884,  0.3131,  0.0066,\n",
       "        -0.0519, -0.0056,  0.0579,  0.1012, -0.1243,  0.083 , -0.4183,\n",
       "        -0.0427,  0.0712,  0.0287, -0.1871, -0.1247,  0.1566,  0.2217,\n",
       "        -0.1775, -0.098 ,  0.1136, -0.106 , -0.0453, -0.019 ,  0.2017,\n",
       "         0.1142, -0.2928,  0.1528,  0.0524,  0.0022, -0.0278,  0.1505,\n",
       "        -0.0725, -0.0223,  0.0199, -0.1153, -0.1815,  0.0347,  0.0764,\n",
       "        -0.0858, -0.0025, -0.1657, -0.8152, -0.0864, -0.1533,  0.1194,\n",
       "        -0.3305,  0.1837,  0.0033, -0.2619,  0.2675,  0.0445, -0.0677,\n",
       "        -0.0088,  0.0541, -0.1184, -0.1104,  0.1671, -0.0182, -0.0705,\n",
       "         0.0373,  0.2241,  0.0436, -0.1613,  0.1704,  0.0038, -0.208 ,\n",
       "         0.1436,  0.1376, -0.0396,  0.0225,  0.0136, -0.0225,  0.0178,\n",
       "         0.2183, -0.0283,  0.0361, -0.0037,  0.1404, -0.1559, -0.0277,\n",
       "         0.0313, -0.1913, -0.1461, -0.0352,  0.0466,  0.0083,  0.114 ,\n",
       "        -0.0682, -0.0561, -0.0299, -0.153 , -0.1298, -0.0221,  0.0068,\n",
       "         0.1588, -0.1528, -0.0264,  0.0121,  0.135 , -0.0761, -0.0096,\n",
       "        -0.02  ,  0.0562, -0.1439, -0.0598, -0.0573, -0.1558,  0.097 ,\n",
       "        -0.1344, -0.0838,  0.0012, -0.2129,  0.0585, -0.0222, -0.0459,\n",
       "         0.0239,  0.0123, -0.1877,  0.0729, -0.2697,  0.1091,  0.1785,\n",
       "         0.1139,  0.101 , -0.175 ,  0.3105, -0.0701, -0.18  , -0.0063,\n",
       "         0.0426,  0.    , -0.2429,  0.0492,  0.1008, -0.0591,  0.1174,\n",
       "         0.1981, -0.1006, -0.1897, -0.1759,  0.0822,  0.1623,  0.3981,\n",
       "        -0.0797,  0.2355,  0.1359,  0.055 ,  0.13  , -0.0778,  0.1565,\n",
       "        -0.2784, -0.0972,  0.0419,  0.0851, -0.0232, -0.025 ,  0.0869,\n",
       "        -0.2116, -0.0288, -0.0735,  0.0063, -0.064 ,  0.0404,  0.1231,\n",
       "         0.085 ,  0.2599,  0.2255, -0.2677, -0.04  ,  0.0588,  0.0164,\n",
       "         0.0517,  0.1859, -0.0401,  0.1147,  0.0316, -0.2496, -0.1453,\n",
       "         0.1274,  0.1448, -0.0702,  0.2039,  0.0516, -0.0287, -0.2759,\n",
       "        -0.0541,  0.0575, -0.12  , -0.1038, -0.1025, -0.1986,  0.033 ,\n",
       "         0.1446,  0.0437,  0.1422, -0.3519, -0.0651, -0.075 , -0.1529,\n",
       "         0.2521,  0.1341, -0.1182, -0.1077, -0.049 ,  0.0785,  0.1337,\n",
       "         0.039 , -0.0122,  0.0352,  0.1772, -0.1827, -0.0589, -0.2745,\n",
       "        -0.0246,  0.0871, -0.0683,  0.1316,  0.0252, -0.06  ,  0.2891,\n",
       "        -0.3413,  0.1113, -0.0991, -0.0681,  0.0086, -0.0134,  0.1637,\n",
       "        -0.0158,  0.1438, -0.0301,  0.0727,  0.0795,  0.2632,  0.0242,\n",
       "        -0.0726,  0.0097,  0.2018, -0.022 , -0.0115,  0.0126, -0.0211,\n",
       "         0.3145, -0.0862,  0.0737,  0.11  ,  0.0048, -0.1378, -0.2332,\n",
       "        -0.0284,  0.0045,  0.0923, -0.1721,  0.1486, -0.3852, -0.0063,\n",
       "        -0.159 , -0.1801, -0.2744, -0.0089,  0.0086,  0.1338,  0.0577,\n",
       "        -0.0958,  0.0402,  0.152 ,  0.0567, -0.148 ,  0.0289, -0.0155,\n",
       "         0.1694, -0.1443, -0.0677, -0.0121, -0.1023,  0.0197, -0.068 ,\n",
       "        -0.1042,  0.089 , -0.0603,  0.2254, -0.0693,  0.0104,  0.254 ,\n",
       "        -0.0578, -0.0033, -0.078 ,  0.0748,  0.0415,  0.0603],\n",
       "       dtype=float32),\n",
       " array([ 3.400e-03, -1.834e-01,  4.350e-02, -7.490e-02,  1.602e-01,\n",
       "         2.750e-02,  1.591e-01,  8.920e-02, -8.010e-02, -1.231e-01,\n",
       "        -8.620e-02, -5.500e-03,  1.069e-01,  1.670e-01,  1.990e-02,\n",
       "        -1.685e-01,  9.650e-02,  9.130e-02,  2.450e-02, -1.081e-01,\n",
       "        -2.186e-01,  1.368e-01,  2.320e-02, -2.143e-01,  9.850e-02,\n",
       "         6.180e-02, -1.355e-01,  3.880e-02,  6.000e-02, -2.280e-01,\n",
       "        -6.830e-02, -1.652e-01, -3.640e-02, -1.802e-01,  2.211e-01,\n",
       "         1.419e-01, -6.730e-02, -1.600e-02, -2.130e-02,  2.340e-02,\n",
       "        -9.570e-02,  3.640e-02, -1.544e-01,  1.534e-01, -7.000e-04,\n",
       "        -1.217e-01,  1.112e-01, -2.790e-02, -1.970e-02,  1.704e-01,\n",
       "         8.970e-02, -6.170e-02, -7.707e-01, -3.990e-02,  1.057e-01,\n",
       "        -6.450e-02, -1.459e-01, -1.174e-01,  1.860e-01,  4.750e-02,\n",
       "         4.450e-02, -1.980e-02,  1.532e-01,  2.390e-01,  1.097e-01,\n",
       "        -1.166e-01, -3.140e-02,  5.030e-02, -8.940e-02,  2.530e-02,\n",
       "         1.135e-01, -1.121e-01,  4.760e-02, -4.060e-02, -8.880e-02,\n",
       "         8.260e-02, -3.100e-02, -2.243e-01,  1.158e-01,  1.248e-01,\n",
       "         3.400e-02,  1.078e-01, -4.420e-02, -1.761e-01,  1.263e-01,\n",
       "         1.183e-01,  8.200e-02, -1.325e-01,  3.939e-01,  3.390e-02,\n",
       "         2.175e-01, -3.910e-02, -8.120e-02,  7.940e-02,  3.460e-02,\n",
       "         2.480e-02,  1.679e-01, -6.690e-02, -3.380e-02, -3.460e-02,\n",
       "        -1.453e-01, -1.266e-01, -1.816e-01,  9.570e-02, -6.000e-04,\n",
       "        -3.560e-02,  4.100e-02, -4.950e-02, -3.180e-02,  1.033e-01,\n",
       "        -6.850e-02,  2.944e-01, -4.090e-02,  1.822e-01,  1.045e-01,\n",
       "        -2.786e-01,  8.430e-02, -2.750e-02,  1.919e-01, -2.832e-01,\n",
       "        -1.220e-02,  1.665e-01,  8.070e-02,  3.850e-02, -5.130e-02,\n",
       "         1.327e-01,  2.063e-01, -2.660e-02,  7.000e-03,  1.399e-01,\n",
       "         4.710e-02, -1.167e-01,  8.430e-02, -3.770e-02,  1.174e-01,\n",
       "        -8.920e-02, -5.800e-03, -2.230e-02,  1.577e-01,  4.180e-02,\n",
       "         1.910e-02, -1.617e-01,  1.550e-01,  2.206e-01,  9.090e-02,\n",
       "        -6.880e-02,  1.851e-01, -6.240e-02, -7.820e-02,  5.060e-02,\n",
       "        -1.847e-01,  2.770e-02,  5.850e-02,  2.350e-02, -1.444e-01,\n",
       "        -6.250e-02, -6.920e-02,  1.032e-01, -1.322e-01, -1.051e-01,\n",
       "        -7.430e-02, -2.705e-01,  7.100e-02,  1.754e-01,  1.218e-01,\n",
       "         3.100e-03,  5.650e-02, -8.230e-02, -1.956e-01, -4.700e-03,\n",
       "         7.580e-02, -8.400e-03, -2.700e-03, -3.590e-02,  1.900e-01,\n",
       "         2.090e-02,  2.891e-01, -2.136e-01,  1.212e-01, -7.490e-02,\n",
       "        -2.190e-02, -9.570e-02, -1.690e-02,  9.570e-02, -1.630e-01,\n",
       "         6.500e-02,  1.303e-01, -3.640e-02, -1.035e-01,  6.840e-02,\n",
       "        -1.054e-01,  6.900e-03,  9.770e-02,  1.149e-01,  1.035e-01,\n",
       "        -1.935e-01,  6.900e-02, -1.368e-01,  6.730e-02,  5.160e-02,\n",
       "        -3.360e-02,  1.459e-01,  1.394e-01,  6.430e-02, -6.740e-02,\n",
       "         2.190e-02,  1.625e-01, -3.860e-02,  4.150e-02,  6.590e-02,\n",
       "         8.910e-02, -1.620e-02,  5.860e-02,  3.140e-02, -8.540e-02,\n",
       "         4.770e-02, -8.040e-02, -1.456e-01, -2.705e-01, -7.880e-02,\n",
       "        -3.830e-02,  5.300e-02, -8.800e-02, -2.540e-02,  8.400e-03,\n",
       "        -1.624e-01,  3.520e-02, -8.340e-02, -7.490e-02, -1.658e-01,\n",
       "         9.130e-02, -2.347e-01,  2.495e-01,  2.530e-02,  4.880e-02,\n",
       "        -1.926e-01,  1.120e-02, -7.850e-02, -1.927e-01, -6.500e-02,\n",
       "        -1.449e-01,  3.070e-02,  5.280e-02,  1.032e-01,  2.380e-02,\n",
       "        -8.010e-02,  1.879e-01,  4.860e-02, -7.700e-02,  3.854e-01,\n",
       "        -9.900e-03,  1.406e-01,  7.510e-02,  1.194e-01,  9.740e-02,\n",
       "        -7.570e-02, -5.860e-02, -7.670e-02, -1.130e-01, -2.980e-02,\n",
       "         7.820e-02,  1.320e-02,  9.900e-03,  5.320e-02, -1.956e-01,\n",
       "         5.600e-02,  1.120e-02,  4.600e-02, -3.282e-01,  5.110e-02,\n",
       "        -1.256e-01,  2.050e-02,  2.776e-01, -8.300e-03,  7.710e-02,\n",
       "         1.052e-01,  1.620e-02,  2.180e-01,  3.980e-02, -1.038e-01,\n",
       "         1.830e-02,  2.154e-01, -4.900e-03,  8.990e-02, -2.510e-02,\n",
       "         6.650e-02, -1.680e-02, -1.068e-01,  1.208e-01,  1.086e-01,\n",
       "         1.553e-01, -1.036e-01, -4.800e-02, -1.764e-01, -6.940e-02,\n",
       "        -1.142e-01,  2.940e-02,  7.620e-02, -4.530e-02,  3.400e-02],\n",
       "       dtype=float32),\n",
       " array([ 8.350e-02, -1.590e-01,  1.930e-02,  2.180e-02, -7.470e-02,\n",
       "         2.350e-02,  3.024e-01,  1.100e-02, -7.410e-02, -9.550e-02,\n",
       "        -1.250e-02,  5.930e-02,  3.230e-02, -6.470e-02, -5.400e-03,\n",
       "        -1.490e-02,  1.134e-01, -4.100e-03,  5.920e-02, -3.690e-02,\n",
       "        -2.109e-01, -1.680e-02,  9.780e-02,  1.468e-01,  7.060e-02,\n",
       "        -1.844e-01,  5.490e-02,  1.041e-01,  8.540e-02, -3.050e-02,\n",
       "         5.350e-02,  5.430e-02, -2.060e-02, -1.528e-01,  1.809e-01,\n",
       "        -5.340e-02, -1.910e-02,  1.178e-01, -8.610e-02, -1.018e-01,\n",
       "         1.050e-01,  2.395e-01, -4.110e-02,  3.110e-02,  1.009e-01,\n",
       "         1.389e-01, -1.060e-01,  1.062e-01,  1.331e-01, -9.900e-03,\n",
       "         1.927e-01, -9.800e-03, -6.466e-01, -8.960e-02, -3.120e-02,\n",
       "        -1.860e-02, -6.610e-02,  6.150e-02, -1.263e-01, -6.900e-02,\n",
       "         1.785e-01,  6.440e-02, -1.216e-01, -1.362e-01, -6.800e-03,\n",
       "        -1.126e-01, -4.170e-02,  1.410e-01, -8.260e-02,  9.800e-02,\n",
       "         1.097e-01,  6.870e-02, -3.210e-02, -1.096e-01,  1.164e-01,\n",
       "         5.000e-04, -5.490e-02,  8.530e-02, -4.630e-02,  8.560e-02,\n",
       "        -1.390e-02, -1.500e-02, -9.360e-02, -2.186e-01,  2.472e-01,\n",
       "         8.460e-02, -9.780e-02,  1.908e-01,  1.050e-01, -1.020e-02,\n",
       "        -2.270e-02,  1.918e-01,  4.270e-02, -2.500e-02, -6.330e-02,\n",
       "         7.340e-02,  1.954e-01, -2.081e-01, -1.409e-01,  1.204e-01,\n",
       "        -2.620e-01, -1.075e-01, -1.883e-01, -4.800e-03, -1.900e-03,\n",
       "         1.981e-01, -1.428e-01,  3.400e-03,  2.340e-02,  9.140e-02,\n",
       "         6.360e-02,  8.230e-02, -1.670e-02,  1.238e-01,  6.190e-02,\n",
       "        -2.517e-01, -4.220e-02,  3.390e-02,  3.620e-02, -4.059e-01,\n",
       "        -6.090e-02, -1.330e-01, -7.310e-02, -7.070e-02, -1.146e-01,\n",
       "         2.581e-01,  1.378e-01, -7.980e-02, -1.905e-01,  1.699e-01,\n",
       "        -9.700e-02,  3.620e-02,  3.530e-02,  8.130e-02, -2.760e-02,\n",
       "         1.195e-01,  7.680e-02, -4.190e-02, -4.230e-02,  4.770e-02,\n",
       "        -7.890e-02, -1.367e-01, -1.250e-02,  2.654e-01,  4.480e-02,\n",
       "         4.190e-02,  1.038e-01,  4.220e-02, -8.900e-03, -1.248e-01,\n",
       "         4.650e-02,  1.033e-01,  7.380e-02,  3.483e-01, -8.000e-04,\n",
       "         1.464e-01, -1.910e-02, -1.825e-01,  2.060e-02,  8.380e-02,\n",
       "         2.016e-01,  1.760e-02,  6.330e-02, -2.635e-01,  1.289e-01,\n",
       "        -1.693e-01,  1.233e-01,  8.420e-02, -7.240e-02, -7.240e-02,\n",
       "        -2.392e-01, -3.720e-02, -2.380e-02,  1.072e-01,  7.110e-02,\n",
       "        -1.062e-01,  2.364e-01, -1.128e-01, -2.747e-01,  9.600e-03,\n",
       "         5.800e-03,  9.250e-02,  1.810e-02,  1.337e-01,  4.520e-02,\n",
       "         3.350e-02,  9.850e-02,  1.417e-01, -2.074e-01, -1.030e-02,\n",
       "        -9.130e-02, -3.740e-02,  1.656e-01,  6.730e-02, -8.320e-02,\n",
       "        -6.050e-02,  4.130e-02, -5.890e-02,  1.269e-01,  4.220e-02,\n",
       "        -1.215e-01,  2.150e-02,  9.020e-02,  1.543e-01, -7.970e-02,\n",
       "        -4.300e-03,  6.210e-02, -9.400e-02, -1.174e-01, -2.320e-02,\n",
       "        -6.060e-02, -6.120e-02, -1.266e-01,  7.000e-04, -6.300e-02,\n",
       "        -3.420e-02,  1.591e-01,  7.350e-02, -2.002e-01,  6.120e-02,\n",
       "        -4.480e-02,  1.636e-01, -7.370e-02, -3.890e-02,  1.489e-01,\n",
       "        -1.370e-02, -1.908e-01, -5.840e-02, -7.870e-02,  1.625e-01,\n",
       "        -4.660e-02, -3.080e-02,  3.793e-01, -6.600e-02, -2.119e-01,\n",
       "        -2.440e-02,  1.397e-01,  2.833e-01, -2.985e-01, -2.980e-02,\n",
       "         1.066e-01,  1.517e-01, -4.760e-02,  2.910e-02,  1.479e-01,\n",
       "        -4.850e-02,  4.900e-02,  2.648e-01, -1.434e-01,  4.334e-01,\n",
       "        -1.136e-01, -4.230e-02,  9.190e-02,  3.430e-02,  1.259e-01,\n",
       "        -5.410e-02,  9.360e-02,  8.940e-02, -4.350e-02,  9.610e-02,\n",
       "        -1.995e-01,  2.256e-01,  1.265e-01,  1.167e-01, -4.396e-01,\n",
       "         3.900e-03, -1.400e-01,  1.496e-01, -1.575e-01,  4.180e-02,\n",
       "        -7.210e-02,  7.620e-02,  9.700e-03, -2.118e-01,  1.225e-01,\n",
       "        -1.910e-02,  1.270e-02, -3.220e-02, -6.340e-02,  9.490e-02,\n",
       "         7.340e-02, -8.680e-02, -5.700e-02,  1.510e-01, -1.430e-02,\n",
       "         1.015e-01,  6.080e-02, -1.327e-01,  1.800e-03, -7.450e-02,\n",
       "         3.870e-02, -8.070e-02, -1.484e-01, -1.314e-01, -1.284e-01,\n",
       "         5.970e-02, -3.680e-02,  5.600e-03,  3.830e-02, -1.430e-02],\n",
       "       dtype=float32),\n",
       " array([ 1.241e-01, -8.740e-02,  1.867e-01, -5.140e-02,  1.153e-01,\n",
       "         1.588e-01,  4.160e-02,  5.890e-02,  1.285e-01, -6.800e-02,\n",
       "        -8.810e-02,  3.800e-03,  8.270e-02, -7.480e-02,  2.182e-01,\n",
       "        -1.050e-02,  1.113e-01, -2.500e-02, -1.600e-03, -6.640e-02,\n",
       "        -7.620e-02, -8.800e-02, -4.490e-02,  2.320e-02,  4.400e-03,\n",
       "        -1.308e-01,  7.040e-02,  1.754e-01,  1.466e-01, -1.100e-03,\n",
       "        -2.420e-02,  1.590e-01,  1.632e-01, -3.690e-02,  5.130e-02,\n",
       "        -4.400e-02, -1.234e-01,  1.997e-01,  5.730e-02, -2.140e-02,\n",
       "         1.132e-01,  2.320e-02,  1.501e-01, -6.590e-02, -1.060e-01,\n",
       "         1.465e-01,  1.550e-02, -6.180e-02, -8.000e-02, -1.375e-01,\n",
       "         6.760e-02,  1.900e-02, -6.456e-01, -1.276e-01, -8.640e-02,\n",
       "        -1.230e-02, -6.810e-02, -3.900e-02, -5.060e-02, -6.330e-02,\n",
       "         1.382e-01, -1.181e-01, -3.590e-02,  1.369e-01, -1.790e-02,\n",
       "        -4.680e-02,  5.030e-02,  2.690e-02,  1.479e-01,  5.340e-02,\n",
       "         3.360e-02, -2.088e-01, -3.990e-02, -2.800e-03, -1.889e-01,\n",
       "        -5.170e-02, -2.300e-02,  7.100e-03, -1.068e-01,  1.692e-01,\n",
       "        -5.700e-03,  6.480e-02, -2.970e-02, -2.668e-01, -7.330e-02,\n",
       "        -7.520e-02,  1.910e-02, -6.900e-03,  1.415e-01, -7.720e-02,\n",
       "        -5.330e-02, -2.660e-02, -5.350e-02, -5.000e-03, -1.212e-01,\n",
       "         6.120e-02, -8.180e-02, -2.137e-01, -7.310e-02, -2.640e-02,\n",
       "        -1.398e-01, -1.015e-01,  2.700e-02, -6.240e-02,  4.780e-02,\n",
       "         1.010e-02, -3.180e-02,  7.000e-04, -8.130e-02,  4.030e-02,\n",
       "         1.245e-01,  1.604e-01, -1.021e-01,  5.270e-02,  8.050e-02,\n",
       "        -1.260e-01,  1.073e-01, -1.218e-01,  1.104e-01, -4.174e-01,\n",
       "         2.120e-02,  4.280e-02, -4.270e-02, -6.190e-02, -3.410e-02,\n",
       "         1.893e-01, -5.980e-02, -1.149e-01, -1.978e-01,  1.286e-01,\n",
       "         1.700e-03, -1.109e-01, -4.800e-03, -5.900e-03,  6.460e-02,\n",
       "         1.362e-01,  2.140e-02,  4.940e-02,  8.900e-03, -9.530e-02,\n",
       "        -3.850e-02,  8.100e-03, -9.380e-02,  2.155e-01,  1.123e-01,\n",
       "        -3.820e-02,  3.800e-03, -5.780e-02, -1.400e-03,  5.820e-02,\n",
       "        -1.580e-02,  3.700e-02,  1.890e-02, -3.380e-02,  3.600e-02,\n",
       "         3.960e-02,  1.000e-04, -5.600e-03, -1.320e-02, -4.320e-02,\n",
       "         1.340e-02, -3.110e-02, -4.000e-02,  6.080e-02,  4.830e-02,\n",
       "        -8.700e-03,  1.124e-01,  1.180e-02, -3.440e-02,  5.610e-02,\n",
       "        -2.471e-01, -1.078e-01,  5.160e-02,  2.600e-03,  8.150e-02,\n",
       "        -3.200e-02,  2.700e-01,  3.240e-02, -2.014e-01,  4.020e-02,\n",
       "         5.830e-02,  2.160e-02,  1.085e-01,  1.319e-01, -1.035e-01,\n",
       "        -1.460e-02,  3.320e-02,  8.700e-03, -2.386e-01,  1.720e-02,\n",
       "         1.700e-03, -9.940e-02, -3.810e-02,  9.250e-02,  1.850e-02,\n",
       "        -1.172e-01, -2.019e-01, -2.850e-02,  1.636e-01,  1.647e-01,\n",
       "        -1.673e-01, -1.200e-02, -3.600e-03,  4.520e-02,  1.510e-01,\n",
       "         7.990e-02,  1.055e-01, -1.003e-01,  1.539e-01, -3.370e-02,\n",
       "         1.740e-02, -2.250e-02,  2.040e-02, -9.630e-02, -1.330e-01,\n",
       "        -6.800e-02, -7.000e-03, -1.134e-01, -7.020e-02, -5.930e-02,\n",
       "         4.250e-02,  3.190e-02, -2.260e-02,  4.810e-02,  1.348e-01,\n",
       "        -1.128e-01, -3.430e-02,  8.560e-02, -1.639e-01,  9.920e-02,\n",
       "         5.520e-02, -3.016e-01,  4.949e-01, -7.500e-02,  7.610e-02,\n",
       "        -2.910e-02, -4.310e-02,  2.132e-01, -2.819e-01,  9.640e-02,\n",
       "        -2.880e-02, -1.370e-02,  7.210e-02,  1.665e-01,  1.800e-02,\n",
       "        -2.940e-02,  1.228e-01,  3.250e-02,  1.500e-03,  4.141e-01,\n",
       "         8.600e-03,  1.406e-01, -3.820e-02,  4.860e-02,  1.335e-01,\n",
       "         1.258e-01, -1.434e-01, -2.490e-02, -6.470e-02,  7.240e-02,\n",
       "         1.290e-02, -8.920e-02,  9.760e-02, -5.020e-02, -3.723e-01,\n",
       "        -8.700e-03, -1.020e-01, -6.540e-02, -2.127e-01,  1.623e-01,\n",
       "         1.240e-02,  2.910e-02,  7.850e-02, -1.200e-01, -4.030e-02,\n",
       "        -2.830e-02, -5.700e-02, -1.302e-01,  7.740e-02, -4.610e-02,\n",
       "         6.870e-02, -7.680e-02, -2.790e-02,  3.400e-02, -1.407e-01,\n",
       "         2.480e-02, -2.140e-02, -1.315e-01, -1.750e-02, -5.570e-02,\n",
       "         5.720e-02, -5.170e-02, -8.770e-02,  8.270e-02,  3.200e-02,\n",
       "         1.210e-01,  2.970e-02,  4.760e-02,  5.900e-03, -2.520e-02],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average of the vectors\n",
    "X_avg = []\n",
    "\n",
    "for vector in X:\n",
    "    if len(vector) >= 1:\n",
    "        X_avg.append(np.mean(vector))\n",
    "    else:\n",
    "        X_avg.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_avg = np.array(X_avg)\n",
    "X_avg = X_avg.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00032158],\n",
       "       [-0.00506292],\n",
       "       [-0.004897  ],\n",
       "       [ 0.001083  ],\n",
       "       [-0.00152267]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_avg[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross valudation\n",
    "LR = LogisticRegression()\n",
    "\n",
    "scores = cross_val_score(\n",
    "    LR, \n",
    "    X_avg, \n",
    "    train_labels, \n",
    "    cv = 5, \n",
    "    scoring = 'f1_macro'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4839921463708913"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_score = np.sum(scores) / len(scores)\n",
    "avg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train_text[:100]\n",
    "\n",
    "tokenized_text = [spacy_model(word) for word in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tagging.png\" alt=\"tagging\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speech tagging\n",
    "tagged_text = [{word : word.tag_ for word in sent} for sent in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{how: 'WRB',\n",
       "  did: 'VBD',\n",
       "  quebec: 'NN',\n",
       "  nationalists: 'NNS',\n",
       "  see: 'VBP',\n",
       "  their: 'PRP$',\n",
       "  province: 'NN',\n",
       "  as: 'IN',\n",
       "  a: 'DT',\n",
       "  nation: 'NN',\n",
       "  in: 'IN',\n",
       "  the: 'DT',\n",
       "  1960s: 'NNS',\n",
       "  ?: '.'},\n",
       " {do: 'VBP',\n",
       "  you: 'PRP',\n",
       "  have: 'VB',\n",
       "  an: 'DT',\n",
       "  adopted: 'VBN',\n",
       "  dog: 'NN',\n",
       "  ,: ',',\n",
       "  how: 'WRB',\n",
       "  would: 'MD',\n",
       "  you: 'PRP',\n",
       "  encourage: 'VB',\n",
       "  people: 'NNS',\n",
       "  to: 'TO',\n",
       "  adopt: 'VB',\n",
       "  and: 'CC',\n",
       "  not: 'RB',\n",
       "  shop: 'VB',\n",
       "  ?: '.'},\n",
       " {why: 'WRB',\n",
       "  does: 'VBZ',\n",
       "  velocity: 'NN',\n",
       "  affect: 'VB',\n",
       "  time: 'NN',\n",
       "  ?: '.',\n",
       "  does: 'VBZ',\n",
       "  velocity: 'NN',\n",
       "  affect: 'VB',\n",
       "  space: 'NN',\n",
       "  geometry: 'NN',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  did: 'VBD',\n",
       "  otto: 'JJ',\n",
       "  von: 'NNP',\n",
       "  guericke: 'NN',\n",
       "  used: 'VBD',\n",
       "  the: 'DT',\n",
       "  magdeburg: 'NN',\n",
       "  hemispheres: 'NNS',\n",
       "  ?: '.'},\n",
       " {can: 'MD',\n",
       "  i: 'PRP',\n",
       "  convert: 'VB',\n",
       "  montra: 'JJ',\n",
       "  helicon: 'NN',\n",
       "  d: 'XX',\n",
       "  to: 'IN',\n",
       "  a: 'DT',\n",
       "  mountain: 'NN',\n",
       "  bike: 'NN',\n",
       "  by: 'IN',\n",
       "  just: 'RB',\n",
       "  changing: 'VBG',\n",
       "  the: 'DT',\n",
       "  tyres: 'NNS',\n",
       "  ?: '.'},\n",
       " {is: 'VBZ',\n",
       "  gaza: 'NN',\n",
       "  slowly: 'RB',\n",
       "  becoming: 'VBG',\n",
       "  auschwitz: 'JJ',\n",
       "  ,: ',',\n",
       "  dachau: 'NN',\n",
       "  or: 'CC',\n",
       "  treblinka: 'NN',\n",
       "  for: 'IN',\n",
       "  palestinians: 'NNS',\n",
       "  ?: '.'},\n",
       " {why: 'WRB',\n",
       "  does: 'VBZ',\n",
       "  quora: 'NNP',\n",
       "  automatically: 'RB',\n",
       "  ban: 'VB',\n",
       "  conservative: 'JJ',\n",
       "  opinions: 'NNS',\n",
       "  when: 'WRB',\n",
       "  reported: 'VBN',\n",
       "  ,: ',',\n",
       "  but: 'CC',\n",
       "  does: 'VBZ',\n",
       "  not: 'RB',\n",
       "  do: 'VB',\n",
       "  the: 'DT',\n",
       "  same: 'JJ',\n",
       "  for: 'IN',\n",
       "  liberal: 'JJ',\n",
       "  views: 'NNS',\n",
       "  ?: '.'},\n",
       " {is: 'VBZ',\n",
       "  it: 'PRP',\n",
       "  crazy: 'JJ',\n",
       "  if: 'IN',\n",
       "  i: 'PRP',\n",
       "  wash: 'VBP',\n",
       "  or: 'CC',\n",
       "  wipe: 'VBP',\n",
       "  my: 'PRP$',\n",
       "  groceries: 'NNS',\n",
       "  off: 'RP',\n",
       "  ?: '.',\n",
       "  germs: 'NNS',\n",
       "  are: 'VBP',\n",
       "  everywhere: 'RB',\n",
       "  .: '.'},\n",
       " {is: 'VBZ',\n",
       "  there: 'EX',\n",
       "  such: 'PDT',\n",
       "  a: 'DT',\n",
       "  thing: 'NN',\n",
       "  as: 'IN',\n",
       "  dressing: 'VBG',\n",
       "  moderately: 'RB',\n",
       "  ,: ',',\n",
       "  and: 'CC',\n",
       "  if: 'IN',\n",
       "  so: 'RB',\n",
       "  ,: ',',\n",
       "  how: 'WRB',\n",
       "  is: 'VBZ',\n",
       "  that: 'RB',\n",
       "  different: 'JJ',\n",
       "  than: 'IN',\n",
       "  dressing: 'VBG',\n",
       "  modestly: 'RB',\n",
       "  ?: '.'},\n",
       " {is: 'VBZ',\n",
       "  it: 'PRP',\n",
       "  just: 'RB',\n",
       "  me: 'PRP',\n",
       "  or: 'CC',\n",
       "  have: 'VBP',\n",
       "  you: 'PRP',\n",
       "  ever: 'RB',\n",
       "  been: 'VBN',\n",
       "  in: 'IN',\n",
       "  this: 'DT',\n",
       "  phase: 'NN',\n",
       "  wherein: 'WRB',\n",
       "  you: 'PRP',\n",
       "  became: 'VBD',\n",
       "  ignorant: 'JJ',\n",
       "  to: 'IN',\n",
       "  the: 'DT',\n",
       "  people: 'NNS',\n",
       "  you: 'PRP',\n",
       "  once: 'RB',\n",
       "  loved: 'VBD',\n",
       "  ,: ',',\n",
       "  completely: 'RB',\n",
       "  disregarding: 'VBG',\n",
       "  their: 'PRP$',\n",
       "  feelings: 'NNS',\n",
       "  /: 'SYM',\n",
       "  lives: 'NNS',\n",
       "  so: 'IN',\n",
       "  you: 'PRP',\n",
       "  get: 'VBP',\n",
       "  to: 'TO',\n",
       "  have: 'VB',\n",
       "  something: 'NN',\n",
       "  go: 'VB',\n",
       "  your: 'PRP$',\n",
       "  way: 'NN',\n",
       "  and: 'CC',\n",
       "  feel: 'VB',\n",
       "  temporarily: 'RB',\n",
       "  at: 'IN',\n",
       "  ease: 'NN',\n",
       "  .: '.',\n",
       "  how: 'WRB',\n",
       "  did: 'VBD',\n",
       "  things: 'NNS',\n",
       "  change: 'VB',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  can: 'MD',\n",
       "  you: 'PRP',\n",
       "  say: 'VB',\n",
       "  about: 'IN',\n",
       "  feminism: 'NN',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  were: 'VBD',\n",
       "  the: 'DT',\n",
       "  calgary: 'NN',\n",
       "  flames: 'NNS',\n",
       "  founded: 'VBN',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  is: 'VBZ',\n",
       "  the: 'DT',\n",
       "  dumbest: 'JJS',\n",
       "  ,: ',',\n",
       "  yet: 'CC',\n",
       "  possibly: 'RB',\n",
       "  true: 'JJ',\n",
       "  explanation: 'NN',\n",
       "  for: 'IN',\n",
       "  trump: 'NN',\n",
       "  being: 'VBG',\n",
       "  elected: 'VBN',\n",
       "  ?: '.'},\n",
       " {can: 'MD',\n",
       "  we: 'PRP',\n",
       "  use: 'VB',\n",
       "  our: 'PRP$',\n",
       "  external: 'JJ',\n",
       "  hard: 'JJ',\n",
       "  disk: 'NN',\n",
       "  as: 'IN',\n",
       "  a: 'DT',\n",
       "  os: 'NN',\n",
       "  as: 'RB',\n",
       "  well: 'RB',\n",
       "  as: 'IN',\n",
       "  for: 'IN',\n",
       "  data: 'NNS',\n",
       "  storage.will: 'IN',\n",
       "  the: 'DT',\n",
       "  data: 'NNS',\n",
       "  be: 'VB',\n",
       "  affected: 'VBN',\n",
       "  ?: '.'},\n",
       " {i: 'PRP',\n",
       "  am: 'VBP',\n",
       "  30: 'CD',\n",
       "  ,: ',',\n",
       "  living: 'VBG',\n",
       "  at: 'IN',\n",
       "  home: 'NN',\n",
       "  and: 'CC',\n",
       "  have: 'VBP',\n",
       "  no: 'DT',\n",
       "  boyfriend: 'NN',\n",
       "  .: '.',\n",
       "  i: 'PRP',\n",
       "  would: 'MD',\n",
       "  love: 'VB',\n",
       "  a: 'DT',\n",
       "  boyfriend: 'NN',\n",
       "  and: 'CC',\n",
       "  my: 'PRP$',\n",
       "  own: 'JJ',\n",
       "  home: 'NN',\n",
       "  .: '.',\n",
       "  how: 'WRB',\n",
       "  can: 'MD',\n",
       "  i: 'PRP',\n",
       "  progress: 'VB',\n",
       "  my: 'PRP$',\n",
       "  situation: 'NN',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  do: 'VBP',\n",
       "  you: 'PRP',\n",
       "  know: 'VB',\n",
       "  about: 'IN',\n",
       "  bram: 'NN',\n",
       "  fischer: 'NN',\n",
       "  and: 'CC',\n",
       "  the: 'DT',\n",
       "  rivonia: 'NN',\n",
       "  trial: 'NN',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  difficult: 'JJ',\n",
       "  is: 'VBZ',\n",
       "  it: 'PRP',\n",
       "  to: 'TO',\n",
       "  find: 'VB',\n",
       "  a: 'DT',\n",
       "  good: 'JJ',\n",
       "  instructor: 'NN',\n",
       "  to: 'TO',\n",
       "  take: 'VB',\n",
       "  a: 'DT',\n",
       "  class: 'NN',\n",
       "  near: 'IN',\n",
       "  you: 'PRP',\n",
       "  ?: '.'},\n",
       " {have: 'VBP',\n",
       "  you: 'PRP',\n",
       "  licked: 'VBN',\n",
       "  the: 'DT',\n",
       "  skin: 'NN',\n",
       "  of: 'IN',\n",
       "  a: 'DT',\n",
       "  corpse: 'NN',\n",
       "  ?: '.'},\n",
       " {do: 'VBP',\n",
       "  you: 'PRP',\n",
       "  think: 'VB',\n",
       "  amazon: 'PRP',\n",
       "  will: 'MD',\n",
       "  adopt: 'VB',\n",
       "  an: 'DT',\n",
       "  in: 'IN',\n",
       "  house: 'NN',\n",
       "  approach: 'NN',\n",
       "  to: 'IN',\n",
       "  manufacturing: 'VBG',\n",
       "  similar: 'JJ',\n",
       "  to: 'IN',\n",
       "  the: 'DT',\n",
       "  tesla: 'NN',\n",
       "  or: 'CC',\n",
       "  space: 'NN',\n",
       "  x: 'SYM',\n",
       "  business: 'NN',\n",
       "  models: 'NNS',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  many: 'JJ',\n",
       "  baronies: 'NNS',\n",
       "  might: 'MD',\n",
       "  exist: 'VB',\n",
       "  within: 'IN',\n",
       "  a: 'DT',\n",
       "  county: 'NN',\n",
       "  palatine: 'NN',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  i: 'PRP',\n",
       "  know: 'VBP',\n",
       "  whether: 'IN',\n",
       "  a: 'DT',\n",
       "  girl: 'NN',\n",
       "  had: 'VBD',\n",
       "  done: 'VBN',\n",
       "  sex: 'NN',\n",
       "  before: 'IN',\n",
       "  sex: 'NN',\n",
       "  with: 'IN',\n",
       "  me: 'PRP',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  do: 'VBP',\n",
       "  i: 'PRP',\n",
       "  become: 'VB',\n",
       "  a: 'DT',\n",
       "  fast: 'JJ',\n",
       "  learner: 'NN',\n",
       "  both: 'DT',\n",
       "  in: 'IN',\n",
       "  my: 'PRP$',\n",
       "  professional: 'JJ',\n",
       "  career: 'NN',\n",
       "  and: 'CC',\n",
       "  in: 'IN',\n",
       "  my: 'PRP$',\n",
       "  personal: 'JJ',\n",
       "  life: 'NN',\n",
       "  ?: '.'},\n",
       " {has: 'VBZ',\n",
       "  the: 'DT',\n",
       "  united: 'JJ',\n",
       "  states: 'NNS',\n",
       "  become: 'VBP',\n",
       "  the: 'DT',\n",
       "  largest: 'JJS',\n",
       "  dictatorship: 'NN',\n",
       "  in: 'IN',\n",
       "  the: 'DT',\n",
       "  world: 'NN',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  is: 'VBZ',\n",
       "  the: 'DT',\n",
       "  strangest: 'JJS',\n",
       "  phenomenon: 'NN',\n",
       "  you: 'PRP',\n",
       "  know: 'VBP',\n",
       "  of: 'IN',\n",
       "  ,: ',',\n",
       "  have: 'VBP',\n",
       "  witnessed: 'VBN',\n",
       "  or: 'CC',\n",
       "  have: 'VBP',\n",
       "  generated: 'VBN',\n",
       "  in: 'IN',\n",
       "  the: 'DT',\n",
       "  area: 'NN',\n",
       "  of: 'IN',\n",
       "  electronics: 'NNS',\n",
       "  that: 'WDT',\n",
       "  has: 'VBZ',\n",
       "  no: 'DT',\n",
       "  explanation: 'NN',\n",
       "  in: 'IN',\n",
       "  terms: 'NNS',\n",
       "  of: 'IN',\n",
       "  modern: 'JJ',\n",
       "  physics: 'NN',\n",
       "  ?: '.'},\n",
       " {should: 'MD',\n",
       "  i: 'PRP',\n",
       "  leave: 'VB',\n",
       "  my: 'PRP$',\n",
       "  friends: 'NNS',\n",
       "  and: 'CC',\n",
       "  find: 'VB',\n",
       "  new: 'JJ',\n",
       "  ones: 'NNS',\n",
       "  ?: '.'},\n",
       " {can: 'MD',\n",
       "  you: 'PRP',\n",
       "  make: 'VB',\n",
       "  amazon: 'NN',\n",
       "  alexa: 'JJ',\n",
       "  trigger: 'VB',\n",
       "  events: 'NNS',\n",
       "  in: 'IN',\n",
       "  the: 'DT',\n",
       "  browser: 'NN',\n",
       "  ?: '.'},\n",
       " {why: 'WRB',\n",
       "  have: 'VBP',\n",
       "  n't: 'RB',\n",
       "  two: 'CD',\n",
       "  democracies: 'NNS',\n",
       "  never: 'RB',\n",
       "  ever: 'RB',\n",
       "  went: 'VBD',\n",
       "  for: 'IN',\n",
       "  a: 'DT',\n",
       "  full: 'RB',\n",
       "  fledged: 'JJ',\n",
       "  war: 'NN',\n",
       "  ?: '.',\n",
       "  what: 'WP',\n",
       "  stops: 'VBZ',\n",
       "  them: 'PRP',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  can: 'MD',\n",
       "  i: 'PRP',\n",
       "  top: 'JJ',\n",
       "  cbse: 'NNS',\n",
       "  in: 'IN',\n",
       "  6: 'CD',\n",
       "  months: 'NNS',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  should: 'MD',\n",
       "  i: 'PRP',\n",
       "  know: 'VB',\n",
       "  before: 'IN',\n",
       "  visiting: 'VBG',\n",
       "  mcleodganj: 'NNS',\n",
       "  and: 'CC',\n",
       "  doing: 'VBG',\n",
       "  the: 'DT',\n",
       "  triund: 'NN',\n",
       "  trek: 'NN',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  do: 'VBP',\n",
       "  modern: 'JJ',\n",
       "  military: 'JJ',\n",
       "  submarines: 'NNS',\n",
       "  reduce: 'VBP',\n",
       "  noise: 'NN',\n",
       "  to: 'TO',\n",
       "  achieve: 'VB',\n",
       "  stealth: 'NN',\n",
       "  ?: '.'},\n",
       " {which: 'WDT',\n",
       "  babies: 'NNS',\n",
       "  are: 'VBP',\n",
       "  more: 'RBR',\n",
       "  sweeter: 'JJR',\n",
       "  to: 'IN',\n",
       "  their: 'PRP$',\n",
       "  parents: 'NNS',\n",
       "  ?: '.',\n",
       "  dark: 'JJ',\n",
       "  skin: 'NN',\n",
       "  babies: 'NNS',\n",
       "  or: 'CC',\n",
       "  light: 'JJ',\n",
       "  skin: 'NN',\n",
       "  babies: 'NNS',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  can: 'MD',\n",
       "  i: 'PRP',\n",
       "  remove: 'VB',\n",
       "  black: 'JJ',\n",
       "  heads: 'NNS',\n",
       "  which: 'WDT',\n",
       "  are: 'VBP',\n",
       "  all: 'RB',\n",
       "  over: 'IN',\n",
       "  my: 'PRP$',\n",
       "  nose: 'NN',\n",
       "  ?: '.'},\n",
       " {if: 'IN',\n",
       "  lightsabers: 'NNS',\n",
       "  are: 'VBP',\n",
       "  created: 'VBN',\n",
       "  by: 'IN',\n",
       "  individual: 'JJ',\n",
       "  wielders: 'NNS',\n",
       "  ,: ',',\n",
       "  does: 'VBZ',\n",
       "  each: 'DT',\n",
       "  saber: 'NN',\n",
       "  have: 'VB',\n",
       "  unique: 'JJ',\n",
       "  powers: 'NNS',\n",
       "  /: 'SYM',\n",
       "  abilities: 'NNS',\n",
       "  ?: '.'},\n",
       " {is: 'VBZ',\n",
       "  anyone: 'NN',\n",
       "  still: 'RB',\n",
       "  using: 'VBG',\n",
       "  visual: 'JJ',\n",
       "  basic: 'JJ',\n",
       "  ?: '.',\n",
       "  is: 'VBZ',\n",
       "  it: 'PRP',\n",
       "  worth: 'JJ',\n",
       "  learning: 'VBG',\n",
       "  in: 'IN',\n",
       "  2018: 'CD',\n",
       "  ?: '.',\n",
       "  would: 'MD',\n",
       "  there: 'EX',\n",
       "  be: 'VB',\n",
       "  professional: 'JJ',\n",
       "  jobs: 'NNS',\n",
       "  for: 'IN',\n",
       "  visual: 'JJ',\n",
       "  basic: 'JJ',\n",
       "  programmers: 'NNS',\n",
       "  in: 'IN',\n",
       "  2018: 'CD',\n",
       "  -: 'SYM',\n",
       "  19: 'CD',\n",
       "  -: 'SYM',\n",
       "  20: 'CD',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  is: 'VBZ',\n",
       "  sykes: 'VBZ',\n",
       "  enterprises: 'NNS',\n",
       "  all: 'RB',\n",
       "  about: 'IN',\n",
       "  ?: '.'},\n",
       " {is: 'VBZ',\n",
       "  there: 'EX',\n",
       "  any: 'DT',\n",
       "  clear: 'JJ',\n",
       "  relations: 'NNS',\n",
       "  between: 'IN',\n",
       "  the: 'DT',\n",
       "  number: 'NN',\n",
       "  of: 'IN',\n",
       "  nodes: 'NNS',\n",
       "  /: 'SYM',\n",
       "  dofs: 'NN',\n",
       "  and: 'CC',\n",
       "  the: 'DT',\n",
       "  computational: 'JJ',\n",
       "  performances: 'NNS',\n",
       "  and: 'CC',\n",
       "  requirements: 'NNS',\n",
       "  in: 'IN',\n",
       "  fea: 'NN',\n",
       "  or: 'CC',\n",
       "  cfd: 'NN',\n",
       "  analyses: 'NNS',\n",
       "  (: '-LRB-',\n",
       "  for: 'IN',\n",
       "  ansys: 'NNS',\n",
       "  solutions: 'NNS',\n",
       "  in: 'IN',\n",
       "  particular: 'JJ',\n",
       "  ): '-RRB-',\n",
       "  ?: '.'},\n",
       " {why: 'WRB',\n",
       "  my: 'PRP$',\n",
       "  package: 'NN',\n",
       "  still: 'RB',\n",
       "  is: 'VBZ',\n",
       "  isc: 'NN',\n",
       "  since: 'IN',\n",
       "  may: 'MD',\n",
       "  31,2017: 'CD',\n",
       "  and: 'CC',\n",
       "  i: 'PRP',\n",
       "  do: 'VBP',\n",
       "  n't: 'RB',\n",
       "  have: 'VB',\n",
       "  updated: 'VBN',\n",
       "  ?: '.'},\n",
       " {what: 'WP', does: 'VBZ', great: 'JJ', wit: 'NN', mean: 'VB', ?: '.'},\n",
       " {in: 'IN',\n",
       "  your: 'PRP$',\n",
       "  experience: 'NN',\n",
       "  working: 'VBG',\n",
       "  with: 'IN',\n",
       "  realtors: 'NNS',\n",
       "  ,: ',',\n",
       "  what: 'WP',\n",
       "  do: 'VBP',\n",
       "  you: 'PRP',\n",
       "  wish: 'VB',\n",
       "  realtors: 'NNS',\n",
       "  did: 'VBD',\n",
       "  better: 'RBR',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  do: 'VBP',\n",
       "  i: 'PRP',\n",
       "  get: 'VB',\n",
       "  charge: 'NN',\n",
       "  by: 'IN',\n",
       "  contact: 'NN',\n",
       "  ?: '.'},\n",
       " {do: 'VBP',\n",
       "  all: 'DT',\n",
       "  public: 'JJ',\n",
       "  school: 'NN',\n",
       "  teachers: 'NNS',\n",
       "  automatically: 'RB',\n",
       "  get: 'VBP',\n",
       "  vacation: 'NN',\n",
       "  whenever: 'WRB',\n",
       "  they: 'PRP',\n",
       "  ask: 'VBP',\n",
       "  for: 'IN',\n",
       "  it: 'PRP',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  is: 'VBZ',\n",
       "  the: 'DT',\n",
       "  role: 'NN',\n",
       "  of: 'IN',\n",
       "  technology: 'NN',\n",
       "  in: 'IN',\n",
       "  using: 'VBG',\n",
       "  a: 'DT',\n",
       "  resource: 'NN',\n",
       "  ?: '.'},\n",
       " {should: 'MD',\n",
       "  i: 'PRP',\n",
       "  opt: 'VB',\n",
       "  jaypee: 'JJ',\n",
       "  university: 'NN',\n",
       "  guna: 'NN',\n",
       "  for: 'IN',\n",
       "  mechanical: 'JJ',\n",
       "  engineering: 'NN',\n",
       "  ?: '.'},\n",
       " {where: 'WRB',\n",
       "  can: 'MD',\n",
       "  i: 'PRP',\n",
       "  download: 'VB',\n",
       "  microsoft: 'JJ',\n",
       "  word: 'NN',\n",
       "  for: 'IN',\n",
       "  windows: 'NNS',\n",
       "  2.0: 'CD',\n",
       "  in: 'IN',\n",
       "  hungarian: 'JJ',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  do: 'VBP',\n",
       "  i: 'PRP',\n",
       "  need: 'VB',\n",
       "  to: 'TO',\n",
       "  know: 'VB',\n",
       "  about: 'IN',\n",
       "  buying: 'VBG',\n",
       "  a: 'DT',\n",
       "  car: 'NN',\n",
       "  in: 'IN',\n",
       "  south: 'JJ',\n",
       "  africa: 'NN',\n",
       "  as: 'IN',\n",
       "  an: 'DT',\n",
       "  american: 'NN',\n",
       "  ?: '.'},\n",
       " {as: 'IN',\n",
       "  someone: 'NN',\n",
       "  who: 'WP',\n",
       "  did: 'VBD',\n",
       "  n't: 'RB',\n",
       "  enjoy: 'VB',\n",
       "  harry: 'NN',\n",
       "  potter: 'NN',\n",
       "  and: 'CC',\n",
       "  the: 'DT',\n",
       "  order: 'NN',\n",
       "  of: 'IN',\n",
       "  the: 'DT',\n",
       "  phoenix: 'NN',\n",
       "  movie: 'NN',\n",
       "  ,: ',',\n",
       "  can: 'MD',\n",
       "  i: 'PRP',\n",
       "  at: 'IN',\n",
       "  least: 'JJS',\n",
       "  enjoy: 'VB',\n",
       "  the: 'DT',\n",
       "  book: 'NN',\n",
       "  of: 'IN',\n",
       "  it: 'PRP',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  is: 'VBZ',\n",
       "  the: 'DT',\n",
       "  writing: 'NN',\n",
       "  style: 'NN',\n",
       "  of: 'IN',\n",
       "  the: 'DT',\n",
       "  book: 'NN',\n",
       "  \": '``',\n",
       "  how: 'WRB',\n",
       "  to: 'TO',\n",
       "  resist: 'VB',\n",
       "  prince: 'NN',\n",
       "  charming: 'NN',\n",
       "  \": \"''\",\n",
       "  by: 'IN',\n",
       "  linda: 'NNS',\n",
       "  kage: 'JJ',\n",
       "  ?: '.'},\n",
       " {my: 'PRP$',\n",
       "  mother: 'NN',\n",
       "  expects: 'VBZ',\n",
       "  me: 'PRP',\n",
       "  to: 'TO',\n",
       "  memorize: 'VB',\n",
       "  all: 'PDT',\n",
       "  her: 'PRP$',\n",
       "  usernames: 'NNS',\n",
       "  and: 'CC',\n",
       "  passwords: 'NNS',\n",
       "  .: '.',\n",
       "  how: 'WRB',\n",
       "  can: 'MD',\n",
       "  i: 'PRP',\n",
       "  make: 'VB',\n",
       "  her: 'PRP',\n",
       "  more: 'RBR',\n",
       "  responsible: 'JJ',\n",
       "  about: 'IN',\n",
       "  them: 'PRP',\n",
       "  as: 'IN',\n",
       "  i: 'PRP',\n",
       "  will: 'MD',\n",
       "  be: 'VB',\n",
       "  going: 'VBG',\n",
       "  to: 'IN',\n",
       "  college: 'NN',\n",
       "  in: 'IN',\n",
       "  one: 'CD',\n",
       "  year: 'NN',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  is: 'VBZ',\n",
       "  that: 'DT',\n",
       "  movie: 'NN',\n",
       "  in: 'IN',\n",
       "  which: 'WDT',\n",
       "  a: 'DT',\n",
       "  kid: 'NN',\n",
       "  is: 'VBZ',\n",
       "  fooled: 'VBN',\n",
       "  into: 'IN',\n",
       "  thinking: 'NN',\n",
       "  that: 'IN',\n",
       "  germs: 'NNS',\n",
       "  will: 'MD',\n",
       "  kill: 'VB',\n",
       "  him: 'PRP',\n",
       "  and: 'CC',\n",
       "  so: 'RB',\n",
       "  he: 'PRP',\n",
       "  lives: 'VBZ',\n",
       "  in: 'IN',\n",
       "  a: 'DT',\n",
       "  bubble: 'NN',\n",
       "  for: 'IN',\n",
       "  most: 'JJS',\n",
       "  of: 'IN',\n",
       "  his: 'PRP$',\n",
       "  life: 'NN',\n",
       "  ,: ',',\n",
       "  but: 'CC',\n",
       "  then: 'RB',\n",
       "  decides: 'VBZ',\n",
       "  to: 'TO',\n",
       "  travel: 'VB',\n",
       "  the: 'DT',\n",
       "  world: 'NN',\n",
       "  in: 'IN',\n",
       "  a: 'DT',\n",
       "  portable: 'JJ',\n",
       "  germ: 'NN',\n",
       "  -: 'HYPH',\n",
       "  free: 'JJ',\n",
       "  bubble: 'NN',\n",
       "  ?: '.'},\n",
       " {why: 'WRB',\n",
       "  most: 'JJS',\n",
       "  of: 'IN',\n",
       "  the: 'DT',\n",
       "  computer: 'NN',\n",
       "  science: 'NN',\n",
       "  student: 'NN',\n",
       "  buy: 'VBP',\n",
       "  final: 'JJ',\n",
       "  year: 'NN',\n",
       "  project: 'NN',\n",
       "  from: 'IN',\n",
       "  outside: 'RB',\n",
       "  rather: 'RB',\n",
       "  doing: 'VBG',\n",
       "  it: 'PRP',\n",
       "  by: 'IN',\n",
       "  own: 'JJ',\n",
       "  ,: ',',\n",
       "  is: 'VBZ',\n",
       "  our: 'PRP$',\n",
       "  education: 'NN',\n",
       "  system: 'NN',\n",
       "  really: 'RB',\n",
       "  that: 'DT',\n",
       "  week: 'NN',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  are: 'VBP',\n",
       "  some: 'DT',\n",
       "  ways: 'NNS',\n",
       "  to: 'TO',\n",
       "  shorten: 'VB',\n",
       "  your: 'PRP$',\n",
       "  period: 'NN',\n",
       "  ,: ',',\n",
       "  and: 'CC',\n",
       "  what: 'WP',\n",
       "  are: 'VBP',\n",
       "  the: 'DT',\n",
       "  risks: 'NNS',\n",
       "  of: 'IN',\n",
       "  doing: 'VBG',\n",
       "  it: 'PRP',\n",
       "  ?: '.'},\n",
       " {why: 'WRB',\n",
       "  do: 'VBP',\n",
       "  we: 'PRP',\n",
       "  calead: 'VB',\n",
       "  leap: 'NN',\n",
       "  year: 'NN',\n",
       "  .: '.',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  many: 'JJ',\n",
       "  days: 'NNS',\n",
       "  will: 'MD',\n",
       "  it: 'PRP',\n",
       "  take: 'VB',\n",
       "  to: 'TO',\n",
       "  get: 'VB',\n",
       "  rid: 'VBN',\n",
       "  of: 'IN',\n",
       "  spleen: 'VBN',\n",
       "  enlargement: 'NN',\n",
       "  ?: '.'},\n",
       " {which: 'WDT',\n",
       "  machine: 'NN',\n",
       "  learning: 'NN',\n",
       "  techniques: 'NNS',\n",
       "  can: 'MD',\n",
       "  be: 'VB',\n",
       "  used: 'VBN',\n",
       "  to: 'TO',\n",
       "  extract: 'VB',\n",
       "  metadata: 'NN',\n",
       "  (: '-LRB-',\n",
       "  font: 'NN',\n",
       "  color: 'NN',\n",
       "  ,: ',',\n",
       "  size: 'NN',\n",
       "  ,: ',',\n",
       "  indentation: 'NN',\n",
       "  and: 'CC',\n",
       "  alignment: 'NN',\n",
       "  ): '-RRB-',\n",
       "  of: 'IN',\n",
       "  a: 'DT',\n",
       "  word: 'NN',\n",
       "  document: 'NN',\n",
       "  (: '-LRB-',\n",
       "  .docx: 'NFP',\n",
       "  ): '-RRB-',\n",
       "  file: 'NN',\n",
       "  ,: ',',\n",
       "  and: 'CC',\n",
       "  can: 'MD',\n",
       "  it: 'PRP',\n",
       "  be: 'VB',\n",
       "  integrated: 'VBN',\n",
       "  with: 'IN',\n",
       "  a: 'DT',\n",
       "  web: 'NN',\n",
       "  application: 'NN',\n",
       "  ?: '.'},\n",
       " {does: 'VBZ',\n",
       "  it: 'PRP',\n",
       "  work: 'VB',\n",
       "  with: 'IN',\n",
       "  girls: 'NNS',\n",
       "  the: 'DT',\n",
       "  way: 'NN',\n",
       "  hitch: 'NN',\n",
       "  will: 'MD',\n",
       "  smith: 'NN',\n",
       "  asks: 'VBZ',\n",
       "  not: 'RB',\n",
       "  to: 'TO',\n",
       "  dance: 'VB',\n",
       "  too: 'RB',\n",
       "  much: 'JJ',\n",
       "  ?: '.'},\n",
       " {why: 'WRB',\n",
       "  india: 'JJ',\n",
       "  act: 'NN',\n",
       "  1935: 'CD',\n",
       "  was: 'VBD',\n",
       "  so: 'RB',\n",
       "  special: 'JJ',\n",
       "  ?: '.'},\n",
       " {are: 'VBP',\n",
       "  there: 'EX',\n",
       "  any: 'DT',\n",
       "  sports: 'NNS',\n",
       "  that: 'WDT',\n",
       "  you: 'PRP',\n",
       "  do: 'VBP',\n",
       "  n't: 'RB',\n",
       "  like: 'VB',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  do: 'VBP',\n",
       "  dna: 'VB',\n",
       "  and: 'CC',\n",
       "  rna: 'NN',\n",
       "  compare: 'VB',\n",
       "  and: 'CC',\n",
       "  contrast: 'VB',\n",
       "  ?: '.'},\n",
       " {someone: 'NN',\n",
       "  breaks: 'VBZ',\n",
       "  into: 'IN',\n",
       "  your: 'PRP$',\n",
       "  house: 'NN',\n",
       "  you: 'PRP',\n",
       "  shoot: 'VBP',\n",
       "  and: 'CC',\n",
       "  kill: 'VB',\n",
       "  them: 'PRP',\n",
       "  they: 'PRP',\n",
       "  were: 'VBD',\n",
       "  armed: 'VBN',\n",
       "  with: 'IN',\n",
       "  only: 'RB',\n",
       "  a: 'DT',\n",
       "  knife: 'NN',\n",
       "  what: 'WP',\n",
       "  happens: 'VBZ',\n",
       "  now: 'RB',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  can: 'MD',\n",
       "  i: 'PRP',\n",
       "  write: 'VB',\n",
       "  a: 'DT',\n",
       "  biography: 'NN',\n",
       "  about: 'IN',\n",
       "  gianni: 'VB',\n",
       "  versace: 'NN',\n",
       "  ?: '.'},\n",
       " {are: 'VBP',\n",
       "  extroverted: 'VBN',\n",
       "  better: 'JJR',\n",
       "  and: 'CC',\n",
       "  faster: 'RBR',\n",
       "  at: 'IN',\n",
       "  processing: 'NN',\n",
       "  and: 'CC',\n",
       "  expelling: 'VBG',\n",
       "  information: 'NN',\n",
       "  than: 'IN',\n",
       "  introverts: 'NNS',\n",
       "  ?: '.'},\n",
       " {have: 'VBP',\n",
       "  you: 'PRP',\n",
       "  ever: 'RB',\n",
       "  been: 'VBN',\n",
       "  recognized: 'VBN',\n",
       "  at: 'IN',\n",
       "  a: 'DT',\n",
       "  place: 'NN',\n",
       "  very: 'RB',\n",
       "  far: 'RB',\n",
       "  from: 'IN',\n",
       "  your: 'PRP$',\n",
       "  home: 'NN',\n",
       "  ?: '.'},\n",
       " {why: 'WRB',\n",
       "  do: 'VBP',\n",
       "  price: 'NN',\n",
       "  comparison: 'NN',\n",
       "  websites: 'NNS',\n",
       "  work: 'VBP',\n",
       "  well: 'RB',\n",
       "  in: 'IN',\n",
       "  financial: 'JJ',\n",
       "  services: 'NNS',\n",
       "  ?: '.'},\n",
       " {does: 'VBZ',\n",
       "  ragging: 'VBG',\n",
       "  happen: 'VB',\n",
       "  at: 'IN',\n",
       "  nift: 'JJ',\n",
       "  bangalore: 'NN',\n",
       "  ?: '.'},\n",
       " {why: 'WRB',\n",
       "  their: 'PRP$',\n",
       "  are: 'VBP',\n",
       "  so: 'RB',\n",
       "  many: 'JJ',\n",
       "  bad: 'JJ',\n",
       "  reviews: 'NNS',\n",
       "  of: 'IN',\n",
       "  bahubali: 'JJ',\n",
       "  2: 'CD',\n",
       "  on: 'IN',\n",
       "  imdb: 'NNS',\n",
       "  ?: '.'},\n",
       " {is: 'VBZ', swallowing: 'VBG', listerine: 'NN', dangerous: 'JJ', ?: '.'},\n",
       " {what: 'WP',\n",
       "  are: 'VBP',\n",
       "  the: 'DT',\n",
       "  theories: 'NNS',\n",
       "  in: 'IN',\n",
       "  critical: 'JJ',\n",
       "  thinking: 'NN',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  are: 'VBP',\n",
       "  the: 'DT',\n",
       "  biggest: 'JJS',\n",
       "  problems: 'NNS',\n",
       "  ,: ',',\n",
       "  questions: 'NNS',\n",
       "  ,: ',',\n",
       "  doubts: 'VBZ',\n",
       "  that: 'IN',\n",
       "  you: 'PRP',\n",
       "  come: 'VBP',\n",
       "  across: 'IN',\n",
       "  when: 'WRB',\n",
       "  trying: 'VBG',\n",
       "  to: 'TO',\n",
       "  choose: 'VB',\n",
       "  the: 'DT',\n",
       "  paint: 'NN',\n",
       "  color: 'NN',\n",
       "  for: 'IN',\n",
       "  a: 'DT',\n",
       "  room: 'NN',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  can: 'MD',\n",
       "  i: 'PRP',\n",
       "  get: 'VB',\n",
       "  cheap: 'JJ',\n",
       "  flights: 'NNS',\n",
       "  in: 'IN',\n",
       "  edinburgh: 'NN',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  is: 'VBZ',\n",
       "  china: 'NN',\n",
       "  's: 'POS',\n",
       "  new: 'JJ',\n",
       "  chick: 'NN',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  do: 'VBP',\n",
       "  i: 'PRP',\n",
       "  send: 'VB',\n",
       "  large: 'JJ',\n",
       "  picture: 'NN',\n",
       "  files: 'NNS',\n",
       "  through: 'IN',\n",
       "  an: 'DT',\n",
       "  email: 'NN',\n",
       "  ?: '.'},\n",
       " {why: 'WRB',\n",
       "  does: 'VBZ',\n",
       "  n't: 'RB',\n",
       "  ebay: 'VB',\n",
       "  allow: 'VB',\n",
       "  the: 'DT',\n",
       "  sale: 'NN',\n",
       "  of: 'IN',\n",
       "  wwii: 'NN',\n",
       "  purple: 'JJ',\n",
       "  heart: 'NN',\n",
       "  medals: 'NNS',\n",
       "  even: 'RB',\n",
       "  though: 'IN',\n",
       "  they: 'PRP',\n",
       "  have: 'VBP',\n",
       "  categories: 'NNS',\n",
       "  specifically: 'RB',\n",
       "  for: 'IN',\n",
       "  wwii: 'NN',\n",
       "  military: 'JJ',\n",
       "  medals: 'NNS',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  are: 'VBP',\n",
       "  the: 'DT',\n",
       "  characteristics: 'NNS',\n",
       "  that: 'WDT',\n",
       "  define: 'VBP',\n",
       "  isovolumetric: 'JJ',\n",
       "  relaxation: 'NN',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  do: 'VBP',\n",
       "  i: 'PRP',\n",
       "  work: 'VB',\n",
       "  in: 'IN',\n",
       "  cybersecurity: 'NN',\n",
       "  overseas: 'RB',\n",
       "  ?: '.'},\n",
       " {do: 'VBP',\n",
       "  web: 'NN',\n",
       "  developer: 'NN',\n",
       "  refer: 'VB',\n",
       "  to: 'IN',\n",
       "  w3c: 'NNP',\n",
       "  standard: 'JJ',\n",
       "  practice: 'NN',\n",
       "  ?: '.'},\n",
       " {why: 'WRB',\n",
       "  has: 'VBZ',\n",
       "  the: 'DT',\n",
       "  internet: 'NN',\n",
       "  become: 'VB',\n",
       "  a: 'DT',\n",
       "  problem: 'NN',\n",
       "  ?: '.',\n",
       "  why: 'WRB',\n",
       "  do: 'VBP',\n",
       "  we: 'PRP',\n",
       "  rely: 'VB',\n",
       "  on: 'IN',\n",
       "  it: 'PRP',\n",
       "  for: 'IN',\n",
       "  everything: 'NN',\n",
       "  ?: '.'},\n",
       " {can: 'MD',\n",
       "  we: 'PRP',\n",
       "  get: 'VB',\n",
       "  itc: 'RP',\n",
       "  on: 'IN',\n",
       "  charges: 'NNS',\n",
       "  levied: 'VBN',\n",
       "  by: 'IN',\n",
       "  banks: 'NNS',\n",
       "  ?: '.'},\n",
       " {where: 'WRB', is: 'VBZ', muhammed: 'VBN', now: 'RB', ?: '.'},\n",
       " {what: 'WP',\n",
       "  are: 'VBP',\n",
       "  the: 'DT',\n",
       "  services: 'NNS',\n",
       "  that: 'WDT',\n",
       "  can: 'MD',\n",
       "  be: 'VB',\n",
       "  provided: 'VBN',\n",
       "  by: 'IN',\n",
       "  a: 'DT',\n",
       "  food: 'NN',\n",
       "  testing: 'NN',\n",
       "  lab: 'NN',\n",
       "  and: 'CC',\n",
       "  what: 'WP',\n",
       "  are: 'VBP',\n",
       "  their: 'PRP$',\n",
       "  certified: 'VBN',\n",
       "  requirements: 'NNS',\n",
       "  ?: '.'},\n",
       " {is: 'VBZ',\n",
       "  it: 'PRP',\n",
       "  ok: 'JJ',\n",
       "  to: 'TO',\n",
       "  be: 'VB',\n",
       "  solo: 'RB',\n",
       "  your: 'PRP$',\n",
       "  whole: 'JJ',\n",
       "  life: 'NN',\n",
       "  and: 'CC',\n",
       "  pretend: 'VB',\n",
       "  no: 'DT',\n",
       "  one: 'NN',\n",
       "  exists: 'VBZ',\n",
       "  ?: '.',\n",
       "  is: 'VBZ',\n",
       "  there: 'EX',\n",
       "  such: 'JJ',\n",
       "  thing: 'NN',\n",
       "  as: 'IN',\n",
       "  being: 'VBG',\n",
       "  unwanted: 'JJ',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  do: 'VBP',\n",
       "  i: 'PRP',\n",
       "  change: 'VB',\n",
       "  the: 'DT',\n",
       "  owner: 'NN',\n",
       "  of: 'IN',\n",
       "  a: 'DT',\n",
       "  current: 'JJ',\n",
       "  youtube: 'NN',\n",
       "  account: 'NN',\n",
       "  ?: '.',\n",
       "  the: 'DT',\n",
       "  original: 'JJ',\n",
       "  owner: 'NN',\n",
       "  was: 'VBD',\n",
       "  let: 'VBN',\n",
       "  go: 'VB',\n",
       "  and: 'CC',\n",
       "  i: 'PRP',\n",
       "  do: 'VBP',\n",
       "  not: 'RB',\n",
       "  have: 'VB',\n",
       "  access: 'NN',\n",
       "  to: 'TO',\n",
       "  change: 'VB',\n",
       "  anything: 'NN',\n",
       "  .: '.'},\n",
       " {are: 'VBP',\n",
       "  the: 'DT',\n",
       "  archer: 'NN',\n",
       "  characters: 'NNS',\n",
       "  animated: 'VBD',\n",
       "  based: 'VBN',\n",
       "  on: 'IN',\n",
       "  celebrities: 'NNS',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  is: 'VBZ',\n",
       "  the: 'DT',\n",
       "  best: 'JJS',\n",
       "  way: 'NN',\n",
       "  to: 'TO',\n",
       "  propose: 'VB',\n",
       "  a: 'DT',\n",
       "  girl: 'NN',\n",
       "  without: 'IN',\n",
       "  annoying: 'VBG',\n",
       "  her: 'PRP',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  can: 'MD',\n",
       "  $: '$',\n",
       "  500: 'CD',\n",
       "  million: 'CD',\n",
       "  get: 'VB',\n",
       "  you: 'PRP',\n",
       "  in: 'IN',\n",
       "  solar: 'JJ',\n",
       "  power: 'NN',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  are: 'VBP',\n",
       "  the: 'DT',\n",
       "  recommended: 'VBN',\n",
       "  2d: 'CD',\n",
       "  game: 'NN',\n",
       "  engines: 'NNS',\n",
       "  for: 'IN',\n",
       "  a: 'DT',\n",
       "  beginning: 'VBG',\n",
       "  python: 'NN',\n",
       "  programmer: 'NN',\n",
       "  ?: '.'},\n",
       " {is: 'VBZ',\n",
       "  there: 'EX',\n",
       "  such: 'PDT',\n",
       "  a: 'DT',\n",
       "  thing: 'NN',\n",
       "  as: 'IN',\n",
       "  teleological: 'JJ',\n",
       "  pantheism: 'NN',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  are: 'VBP',\n",
       "  some: 'DT',\n",
       "  best: 'JJS',\n",
       "  college: 'NN',\n",
       "  for: 'IN',\n",
       "  aircraft: 'NN',\n",
       "  propulsion(m.s: 'CD',\n",
       "  ): '-RRB-',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  countries: 'NNS',\n",
       "  in: 'IN',\n",
       "  the: 'DT',\n",
       "  world: 'NN',\n",
       "  have: 'VBP',\n",
       "  freedom: 'NN',\n",
       "  of: 'IN',\n",
       "  speech: 'NN',\n",
       "  on: 'IN',\n",
       "  par: 'NN',\n",
       "  with: 'IN',\n",
       "  the: 'DT',\n",
       "  us: 'PRP',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  lead: 'VBP',\n",
       "  to: 'IN',\n",
       "  the: 'DT',\n",
       "  red: 'JJ',\n",
       "  terror: 'NN',\n",
       "  in: 'IN',\n",
       "  ethiopia: 'NN',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  is: 'VBZ',\n",
       "  the: 'DT',\n",
       "  best: 'JJS',\n",
       "  pen: 'NN',\n",
       "  at: 'IN',\n",
       "  low: 'JJ',\n",
       "  cost: 'NN',\n",
       "  in: 'IN',\n",
       "  all: 'DT',\n",
       "  sorts: 'NNS',\n",
       "  of: 'IN',\n",
       "  things: 'NNS',\n",
       "  ?: '.'},\n",
       " {do: 'VBP',\n",
       "  you: 'PRP',\n",
       "  trust: 'VB',\n",
       "  a: 'DT',\n",
       "  business: 'NN',\n",
       "  that: 'WDT',\n",
       "  has: 'VBZ',\n",
       "  a: 'DT',\n",
       "  facebook: 'NN',\n",
       "  page: 'NN',\n",
       "  as: 'IN',\n",
       "  its: 'PRP$',\n",
       "  website: 'NN',\n",
       "  ?: '.'},\n",
       " {should: 'MD',\n",
       "  we: 'PRP',\n",
       "  improve: 'VB',\n",
       "  our: 'PRP$',\n",
       "  piano: 'NN',\n",
       "  skill: 'NN',\n",
       "  by: 'IN',\n",
       "  keep: 'VB',\n",
       "  practicing: 'VBG',\n",
       "  hard: 'JJ',\n",
       "  pieces: 'NNS',\n",
       "  ?: '.',\n",
       "  is: 'VBZ',\n",
       "  that: 'IN',\n",
       "  the: 'DT',\n",
       "  most: 'RBS',\n",
       "  effective: 'JJ',\n",
       "  way: 'NN',\n",
       "  ?: '.'},\n",
       " {i: 'PRP',\n",
       "  wear: 'VBP',\n",
       "  an: 'DT',\n",
       "  insulin: 'NN',\n",
       "  pump: 'NN',\n",
       "  ,: ',',\n",
       "  and: 'CC',\n",
       "  a: 'DT',\n",
       "  lot: 'NN',\n",
       "  of: 'IN',\n",
       "  girls: 'NNS',\n",
       "  do: 'VBP',\n",
       "  n't: 'RB',\n",
       "  like: 'VB',\n",
       "  it: 'PRP',\n",
       "  .: '.',\n",
       "  nick: 'JJ',\n",
       "  jonas: 'NNS',\n",
       "  wears: 'VBZ',\n",
       "  one: 'CD',\n",
       "  and: 'CC',\n",
       "  dated: 'VBN',\n",
       "  selena: 'NN',\n",
       "  gomez: 'NN',\n",
       "  .: '.',\n",
       "  is: 'VBZ',\n",
       "  there: 'EX',\n",
       "  difference: 'NN',\n",
       "  between: 'IN',\n",
       "  me: 'PRP',\n",
       "  and: 'CC',\n",
       "  nick: 'VB',\n",
       "  several: 'JJ',\n",
       "  zeros: 'NNS',\n",
       "  missing: 'VBG',\n",
       "  in: 'IN',\n",
       "  my: 'PRP$',\n",
       "  bank: 'NN',\n",
       "  account: 'NN',\n",
       "  ?: '.'},\n",
       " {will: 'MD',\n",
       "  turkey: 'NN',\n",
       "  be: 'VB',\n",
       "  seperated: 'VBN',\n",
       "  and: 'CC',\n",
       "  give: 'VB',\n",
       "  a: 'DT',\n",
       "  land: 'NN',\n",
       "  to: 'IN',\n",
       "  kurds: 'NNS',\n",
       "  because: 'IN',\n",
       "  of: 'IN',\n",
       "  foreign: 'JJ',\n",
       "  powers: 'NNS',\n",
       "  like: 'IN',\n",
       "  usa: 'NN',\n",
       "  in: 'IN',\n",
       "  the: 'DT',\n",
       "  future: 'NN',\n",
       "  ?: '.'},\n",
       " {r: 'LS',\n",
       "  sq: 'NN',\n",
       "  .: '.',\n",
       "  cos-1: 'JJ',\n",
       "  when: 'WRB',\n",
       "  r=18.5: 'NN',\n",
       "  equals: 'VBZ',\n",
       "  ?: '.'},\n",
       " {who: 'WP',\n",
       "  sings: 'VBZ',\n",
       "  the: 'DT',\n",
       "  song: 'NN',\n",
       "  in: 'IN',\n",
       "  my: 'PRP$',\n",
       "  head: 'NN',\n",
       "  ?: '.'},\n",
       " {can: 'MD',\n",
       "  chronicled: 'VBN',\n",
       "  replace: 'VB',\n",
       "  supply: 'NN',\n",
       "  chain: 'NN',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  can: 'MD',\n",
       "  you: 'PRP',\n",
       "  solve: 'VB',\n",
       "  this: 'DT',\n",
       "  equation: 'NN',\n",
       "  …: '.',\n",
       "  sin(a*t)-b*t=0: 'NN',\n",
       "  ?: '.'},\n",
       " {what: 'WP',\n",
       "  are: 'VBP',\n",
       "  the: 'DT',\n",
       "  demerits: 'NNS',\n",
       "  of: 'IN',\n",
       "  excellence: 'NN',\n",
       "  in: 'IN',\n",
       "  academic: 'JJ',\n",
       "  pursuits: 'NNS',\n",
       "  ?: '.'},\n",
       " {how: 'WRB',\n",
       "  many: 'JJ',\n",
       "  indians: 'NNS',\n",
       "  are: 'VBP',\n",
       "  in: 'IN',\n",
       "  melbourne: 'JJ',\n",
       "  ,: ',',\n",
       "  australia: 'NNS',\n",
       "  ?: '.'}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagged_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dependency parser analyzes the grammatical structure of a sentence, establishing relationships between \"head\" words and words which modify those heads.\n",
    "<br>\n",
    "<img src=\"parsing.png\" alt=\"parsing\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noun chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noun chunks are \"base noun phrases\" – flat phrases that have a noun as their head. You can think of noun chunks as a noun plus the words describing the noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get noun chunks\n",
    "\n",
    "sample_sent = tokenized_text[1]\n",
    "\n",
    "text = []\n",
    "root = []\n",
    "root_dep = []\n",
    "root_head = []\n",
    "\n",
    "for chunk in sample_sent.noun_chunks:\n",
    "    text.append(chunk.text)\n",
    "    root.append(chunk.root.text)\n",
    "    root_dep.append(chunk.root.dep_)\n",
    "    root_head.append(chunk.root.head.text)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        'TEXT': text, \n",
    "        'ROOT.TEXT': root, \n",
    "        'ROOT.DEP': root_dep, \n",
    "        'ROOT.HEAD.TEXT': root_head\n",
    "    })\n",
    "\n",
    "df = df[['TEXT', 'ROOT.TEXT', 'ROOT.DEP', 'ROOT.HEAD.TEXT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you have an adopted dog, how would you encourage people to adopt and not shop?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>ROOT.TEXT</th>\n",
       "      <th>ROOT.DEP</th>\n",
       "      <th>ROOT.HEAD.TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an adopted dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>dobj</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>encourage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>dobj</td>\n",
       "      <td>encourage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TEXT ROOT.TEXT ROOT.DEP ROOT.HEAD.TEXT\n",
       "0             you       you    nsubj           have\n",
       "1  an adopted dog       dog     dobj           have\n",
       "2             you       you    nsubj      encourage\n",
       "3          people    people     dobj      encourage"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sample_sent)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Text</b>: The original noun chunk text.\n",
    "<br>\n",
    "<b>Root text</b>: The original text of the word connecting the noun chunk to the rest of the parse.\n",
    "<br>\n",
    "<b>Root dep</b>: Dependency relation connecting the root to its head.\n",
    "<br>\n",
    "<b>Root head text</b>: The text of the root token's head."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A named entity is a \"real-world object\" that's assigned a name – for example, a person, a country, a product or a book title. spaCy can recognise various types of named entities in a document, by asking the model for a prediction. Because models are statistical and strongly depend on the examples they were trained on, this doesn't always work perfectly and might need some tuning later, depending on your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named entity recognition\n",
    "sample_sent = 'Google was founded in 1998 in California'\n",
    "doc = spacy_model(sample_sent)\n",
    "\n",
    "text = []\n",
    "start = []\n",
    "end = []\n",
    "label = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    text.append(ent.text)\n",
    "    start.append(ent.start_char)\n",
    "    end.append(ent.end_char)\n",
    "    label.append(ent.label_)\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    'TEXT': text, \n",
    "    'START': start, \n",
    "    'END': end, \n",
    "    'LABEL': label\n",
    "})\n",
    "\n",
    "df = df[['TEXT', 'START', 'END', 'LABEL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>START</th>\n",
       "      <th>END</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>California</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TEXT  START  END LABEL\n",
       "0      Google      0    6   ORG\n",
       "1        1998     22   26  DATE\n",
       "2  California     30   40   GPE"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between dog and cat is: 0.509429395198822\n",
      "Similarity between dog and chair is: 0.35649821162223816\n",
      "Similarity between dog and dog is: 1.0\n"
     ]
    }
   ],
   "source": [
    "text = 'dog cat chair'\n",
    "doc = spacy_model(text)\n",
    "\n",
    "token1 = doc[0]\n",
    "token2 = doc[1]\n",
    "token3 = doc[2]\n",
    "\n",
    "\n",
    "print('Similarity between {0} and {1} is: {2}'.format(token1, token2, token1.similarity(token2)))\n",
    "print('Similarity between {0} and {1} is: {2}'.format(token1, token3, token1.similarity(token3)))\n",
    "print('Similarity between {0} and {1} is: {2}'.format(token1, token1, token1.similarity(token1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
